{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# data processing libs\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import json\n",
    "import requests\n",
    "from pyproj import CRS\n",
    "import pyproj\n",
    "\n",
    "from osgeo import gdal\n",
    "from math import ceil, floor\n",
    "\n",
    "# plotting libs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeature\n",
    "from odc.stac import stac_load\n",
    "import planetary_computer\n",
    "import pystac_client\n",
    "import rich.table\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CHANGE HERE ###########\n",
    "network_name = \"various-geographic-locations\"\n",
    "###### CHANGE HERE ###########\n",
    "\n",
    "input_path = r\"..\\1_data\"\n",
    "output_path = r\"..\\3_data_out\"\n",
    "appears_path = \"APPEEARS_subsetting\"\n",
    "SMAPL3_path = \"SPL3SMP_E\"\n",
    "SMAPL4_path = \"SPL4SMGP\"\n",
    "SMAPL4_grid_path = \"SMAPL4SMGP_EASEreference\"\n",
    "MODIS_path = r\".\\MOD15A2H\"\n",
    "modis_ndvi_path = r\".\\MODIS_NDVI\"\n",
    "# os.chdir(\"G:\\Shared drives\\Ryoko and Hilary\\SMSigxSMAP\\analysis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Ease grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"SMAP_L4_SM_lmc_00000000T000000_Vv7032_001.h5\"\n",
    "file_path = os.path.join(input_path, SMAPL4_grid_path, fn)\n",
    "# if os.path.exists(file_path):\n",
    "#     print('The file exists')\n",
    "# else:\n",
    "#     print('The file does NOT exist')\n",
    "# print(file_path)\n",
    "g = gdal.Open(file_path)\n",
    "# subdatasets = g.GetSubDatasets()\n",
    "\n",
    "varname_lat = \"cell_lat\"\n",
    "full_varname_lat = f'HDF5:\"{file_path}\"://{varname_lat}'\n",
    "\n",
    "varname_lon = \"cell_lon\"\n",
    "full_varname_lon = f'HDF5:\"{file_path}\"://{varname_lon}'\n",
    "\n",
    "varname_ease_column = \"cell_column\"\n",
    "full_varname_ease_column = f'HDF5:\"{file_path}\"://{varname_ease_column}'\n",
    "\n",
    "varname_ease_row = \"cell_row\"\n",
    "full_varname_ease_row = f'HDF5:\"{file_path}\"://{varname_ease_row}'\n",
    "\n",
    "ease_lat = rioxarray.open_rasterio(full_varname_lat)\n",
    "ease_lon = rioxarray.open_rasterio(full_varname_lon)\n",
    "ease_column = rioxarray.open_rasterio(full_varname_ease_column)\n",
    "ease_row = rioxarray.open_rasterio(full_varname_ease_row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Appears sample request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'category': 'Nothern Australia (Tropical dry)',\n",
       "  'latitude': -15.345077,\n",
       "  'longitude': 142.94616},\n",
       " {'id': '1',\n",
       "  'category': 'Brazil (Tropical dry)',\n",
       "  'latitude': -14.139373,\n",
       "  'longitude': -58.190676},\n",
       " {'id': '2',\n",
       "  'category': 'Virginia (Mid-lat humid)',\n",
       "  'latitude': 38.966439,\n",
       "  'longitude': -80.646556},\n",
       " {'id': '3',\n",
       "  'category': 'Wisconsin (Mid-lat humid)',\n",
       "  'latitude': 45.644185,\n",
       "  'longitude': -89.904949},\n",
       " {'id': '4',\n",
       "  'category': 'China (Mid-lat humid)',\n",
       "  'latitude': 34.931655,\n",
       "  'longitude': 101.70849},\n",
       " {'id': '5',\n",
       "  'category': 'Brazil (Mid-lat humid)',\n",
       "  'latitude': -7.738738,\n",
       "  'longitude': -51.667379},\n",
       " {'id': '6',\n",
       "  'category': 'South Dacota (Mid-lat dry)',\n",
       "  'latitude': 44.770144,\n",
       "  'longitude': -101.695938},\n",
       " {'id': '7',\n",
       "  'category': 'Zambia (Mid-lat dry)',\n",
       "  'latitude': -17.037961,\n",
       "  'longitude': 25.431202},\n",
       " {'id': '8',\n",
       "  'category': 'Argentina (Mid-lat dry)',\n",
       "  'latitude': -36.019919,\n",
       "  'longitude': -63.137572},\n",
       " {'id': '9',\n",
       "  'category': 'Russia (Mid-lat humid)',\n",
       "  'latitude': 56.148147,\n",
       "  'longitude': 73.041933}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(input_path, appears_path, network_name, f'{network_name}-request.json')\n",
    "with open(file_path, 'r') as infile:\n",
    "    request_content = json.load(infile)\n",
    "coordinates = request_content['params']['coordinates']\n",
    "dates = request_content['params']['dates']\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing0/10 station: Nothern Australia (Tropical dry)\n",
      "The closest cell to the point (-15.345077, 142.94616) is        (-15.32331657409668, 142.9823760986328:        EASE GRID (1026, 3459)),        d=0.04224448278546333 degrees\n",
      "Found: 329 datasets\n",
      "processing0/324: A2021313\n",
      "processing1/324: A2015081\n",
      "processing2/324: A2022017\n",
      "processing3/324: A2015273\n",
      "processing4/324: A2016129\n",
      "processing5/324: A2021001\n",
      "processing6/324: A2019105\n",
      "processing7/324: A2020305\n",
      "processing8/324: A2020153\n",
      "processing9/324: A2016337\n",
      "processing10/324: A2015337\n",
      "processing11/324: A2020361\n",
      "processing12/324: A2015201\n",
      "processing13/324: A2018081\n",
      "processing14/324: A2018169\n",
      "processing15/324: A2019169\n",
      "processing16/324: A2018257\n",
      "processing17/324: A2020289\n",
      "processing18/324: A2019209\n",
      "processing19/324: A2016241\n",
      "processing20/324: A2017169\n",
      "processing21/324: A2021281\n",
      "processing22/324: A2019185\n",
      "processing23/324: A2016073\n",
      "processing24/324: A2018273\n",
      "processing25/324: A2020281\n",
      "processing26/324: A2018297\n",
      "processing27/324: A2022057\n",
      "processing28/324: A2015249\n",
      "processing29/324: A2019257\n",
      "processing30/324: A2022033\n",
      "processing31/324: A2017313\n",
      "processing32/324: A2018073\n",
      "processing33/324: A2018097\n",
      "processing34/324: A2018201\n",
      "processing35/324: A2017281\n",
      "processing36/324: A2020273\n",
      "processing37/324: A2016121\n",
      "processing38/324: A2019113\n",
      "processing39/324: A2021121\n",
      "processing40/324: A2018353\n",
      "processing41/324: A2018321\n",
      "processing42/324: A2016249\n",
      "processing43/324: A2019193\n",
      "processing44/324: A2019073\n",
      "processing45/324: A2015313\n",
      "processing46/324: A2018185\n",
      "processing47/324: A2020097\n",
      "processing48/324: A2018113\n",
      "processing49/324: A2016161\n",
      "processing50/324: A2020297\n",
      "processing51/324: A2016153\n",
      "processing52/324: A2020337\n",
      "processing53/324: A2019329\n",
      "processing54/324: A2016033\n",
      "processing55/324: A2015161\n",
      "processing56/324: A2017321\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 100\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m k, item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(item_for_the_unique_date):\n\u001b[0;32m     90\u001b[0m     \n\u001b[0;32m     91\u001b[0m     \u001b[39m# Read MODIS data from STAC server\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     MODIS_data0 \u001b[39m=\u001b[39m stac_load(\n\u001b[0;32m     93\u001b[0m         [item],\n\u001b[0;32m     94\u001b[0m         crs\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEPSG:4326\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m         bbox\u001b[39m=\u001b[39mbbox\n\u001b[0;32m     98\u001b[0m     )\n\u001b[1;32m--> 100\u001b[0m     MODIS_QA0 \u001b[39m=\u001b[39m stac_load(\n\u001b[0;32m    101\u001b[0m         [item],\n\u001b[0;32m    102\u001b[0m         crs\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEPSG:4326\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    103\u001b[0m         bands\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m500m_16_days_pixel_reliability\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    104\u001b[0m         resolution\u001b[39m=\u001b[39;49m\u001b[39m0.0045\u001b[39;49m,\n\u001b[0;32m    105\u001b[0m         bbox\u001b[39m=\u001b[39;49mbbox\n\u001b[0;32m    106\u001b[0m     )\n\u001b[0;32m    108\u001b[0m     \u001b[39m# MODIS_QA = MODIS_QA0['500m_16_days_pixel_reliability']\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \n\u001b[0;32m    110\u001b[0m     \u001b[39m# Scale the data \u001b[39;00m\n\u001b[0;32m    111\u001b[0m     raster \u001b[39m=\u001b[39m item\u001b[39m.\u001b[39massets[\u001b[39m\"\u001b[39m\u001b[39m500m_16_days_NDVI\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mextra_fields[\u001b[39m\"\u001b[39m\u001b[39mraster:bands\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\odc\\stac\\_load.py:610\u001b[0m, in \u001b[0;36mload\u001b[1;34m(items, bands, groupby, resampling, dtype, chunks, pool, crs, resolution, anchor, geobox, bbox, lon, lat, x, y, like, geopolygon, progress, fail_on_error, stac_cfg, patch_url, preserve_original_order, **kw)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m progress \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     _work \u001b[39m=\u001b[39m progress(SizedIterable(_work, total_tasks))\n\u001b[1;32m--> 610\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m _work:\n\u001b[0;32m    611\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[39mreturn\u001b[39;00m _with_debug_info(ds, tasks\u001b[39m=\u001b[39m_tasks)\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\odc\\stac\\_utils.py:38\u001b[0m, in \u001b[0;36mpmap\u001b[1;34m(func, inputs, pool)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mWrapper for ThreadPoolExecutor.map\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39mif\u001b[39;00m pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mmap\u001b[39m(func, inputs)\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, \u001b[39mint\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\odc\\stac\\_load.py:601\u001b[0m, in \u001b[0;36mload.<locals>._do_one\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m    595\u001b[0m srcs \u001b[39m=\u001b[39m [\n\u001b[0;32m    596\u001b[0m     src\n\u001b[0;32m    597\u001b[0m     \u001b[39mfor\u001b[39;00m src \u001b[39min\u001b[39;00m (_parsed[idx]\u001b[39m.\u001b[39mget(band, \u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m idx, band \u001b[39min\u001b[39;00m task\u001b[39m.\u001b[39msrcs)\n\u001b[0;32m    598\u001b[0m     \u001b[39mif\u001b[39;00m src \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    599\u001b[0m ]\n\u001b[0;32m    600\u001b[0m \u001b[39mwith\u001b[39;00m rio_env(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_rio_env):\n\u001b[1;32m--> 601\u001b[0m     _ \u001b[39m=\u001b[39m _fill_2d_slice(srcs, task\u001b[39m.\u001b[39;49mdst_gbox, task\u001b[39m.\u001b[39;49mcfg, dst_slice)\n\u001b[0;32m    602\u001b[0m t, y, x \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39midx_tyx\n\u001b[0;32m    603\u001b[0m \u001b[39mreturn\u001b[39;00m (task\u001b[39m.\u001b[39mband, t, y, x)\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\odc\\stac\\_load.py:698\u001b[0m, in \u001b[0;36m_fill_2d_slice\u001b[1;34m(srcs, dst_gbox, cfg, dst)\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[39mreturn\u001b[39;00m dst\n\u001b[0;32m    697\u001b[0m src, \u001b[39m*\u001b[39mrest \u001b[39m=\u001b[39m srcs\n\u001b[1;32m--> 698\u001b[0m _roi, pix \u001b[39m=\u001b[39m rio_read(src, cfg, dst_gbox, dst\u001b[39m=\u001b[39;49mdst)\n\u001b[0;32m    700\u001b[0m \u001b[39mfor\u001b[39;00m src \u001b[39min\u001b[39;00m rest:\n\u001b[0;32m    701\u001b[0m     \u001b[39m# first valid pixel takes precedence over others\u001b[39;00m\n\u001b[0;32m    702\u001b[0m     _roi, pix \u001b[39m=\u001b[39m rio_read(src, cfg, dst_gbox)\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\odc\\stac\\_reader.py:186\u001b[0m, in \u001b[0;36mrio_read\u001b[1;34m(src, cfg, dst_geobox, dst)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39mInternal read method.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m _rio_read(src, cfg, dst_geobox, dst)\n\u001b[0;32m    187\u001b[0m \u001b[39mexcept\u001b[39;00m rasterio\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mRasterioIOError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mfail_on_error:\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\odc\\stac\\_reader.py:219\u001b[0m, in \u001b[0;36m_rio_read\u001b[1;34m(src, cfg, dst_geobox, dst)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rio_read\u001b[39m(\n\u001b[0;32m    210\u001b[0m     src: RasterSource,\n\u001b[0;32m    211\u001b[0m     cfg: RasterLoadParams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# if resampling is `nearest` then ignore sub-pixel translation when deciding\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# whether we can just paste source into destination\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     ttol \u001b[39m=\u001b[39m \u001b[39m0.9\u001b[39m \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mnearest \u001b[39melse\u001b[39;00m \u001b[39m0.05\u001b[39m\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mwith\u001b[39;00m rasterio\u001b[39m.\u001b[39;49mopen(src\u001b[39m.\u001b[39;49muri, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, sharing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39mas\u001b[39;00m rdr:\n\u001b[0;32m    220\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(rdr, rasterio\u001b[39m.\u001b[39mDatasetReader)\n\u001b[0;32m    221\u001b[0m         ovr_idx: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\rasterio\\env.py:444\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    441\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[0;32m    443\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\rasterio\\__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m path \u001b[39m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 304\u001b[0m     dataset \u001b[39m=\u001b[39m DatasetReader(path, driver\u001b[39m=\u001b[39;49mdriver, sharing\u001b[39m=\u001b[39;49msharing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    306\u001b[0m     dataset \u001b[39m=\u001b[39m get_writer_for_path(path, driver\u001b[39m=\u001b[39mdriver)(\n\u001b[0;32m    307\u001b[0m         path, mode, driver\u001b[39m=\u001b[39mdriver, sharing\u001b[39m=\u001b[39msharing, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    308\u001b[0m     )\n",
      "File \u001b[1;32mrasterio\\_base.pyx:311\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\raraki8159\\.conda\\envs\\SMAP_v2\\Lib\\site-packages\\rasterio\\_path.py:81\u001b[0m, in \u001b[0;36m_ParsedPath.name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     archive \u001b[39m=\u001b[39m parts\u001b[39m.\u001b[39mpop() \u001b[39mif\u001b[39;00m parts \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m _ParsedPath(path, archive, scheme)\n\u001b[1;32m---> 81\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     83\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The parsed path's original URI\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheme:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(coordinates)): \n",
    "    target_lat = coordinates[i]['latitude']\n",
    "    target_lon = coordinates[i]['longitude']\n",
    "    target_station = coordinates[i]['category'] #.split()[0]\n",
    "    print(f'processing{i}/{len(coordinates)} station: {target_station}')\n",
    "\n",
    "    # %%\n",
    "    distance = np.sqrt((target_lat-ease_lat[0].values)**2+(target_lon-ease_lon[0].values)**2)\n",
    "\n",
    "    minElement  = np.where(abs(distance) == np.nanmin(abs(distance)))\n",
    "    # print(np.nanmin(distance))\n",
    "\n",
    "    if len(minElement[0])!=1:\n",
    "        print('There are more than two closest cells')\n",
    "        \n",
    "    lat_center = ease_lat[0].values[minElement]\n",
    "    lon_center = ease_lon[0].values[minElement]\n",
    "    ease_center_column = ease_column[0].values[minElement]\n",
    "    ease_center_row = ease_row[0].values[minElement]\n",
    "\n",
    "    print(f'The closest cell to the point ({target_lat}, {target_lon}) is\\\n",
    "        ({lat_center[0]}, {lon_center[0]}:\\\n",
    "        EASE GRID ({ease_center_row[0]}, {ease_center_column[0]})),\\\n",
    "        d={distance[minElement][0]} degrees')\n",
    "\n",
    "    bbox_lat_max = (ease_lat[0].values[minElement]+ease_lat[0].values[minElement[0][0]-1][minElement[1][0]])/2\n",
    "    bbox_lat_min = (ease_lat[0].values[minElement]+ease_lat[0].values[minElement[0][0]+1][minElement[1][0]])/2\n",
    "    bbox_lon_max = (ease_lon[0].values[minElement]+ease_lon[0].values[minElement[0][0]][minElement[1][0]+1])/2\n",
    "    bbox_lon_min = (ease_lon[0].values[minElement]+ease_lon[0].values[minElement[0][0]][minElement[1][0]-1])/2\n",
    "\n",
    "    bounding_box = f'{bbox_lon_min[0]},{bbox_lat_min[0]},{bbox_lon_max[0]},{bbox_lat_max[0]}'\n",
    "    # print(bounding_box)\n",
    "\n",
    "    # %%\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=planetary_computer.sign_inplace,\n",
    "    )\n",
    "\n",
    "\n",
    "    def float_round(num, places = 0, direction = floor):\n",
    "        return direction(num * (10**places)) / float(10**places)\n",
    "\n",
    "    buffer=0.2\n",
    "    bbox = [bbox_lon_min[0]-buffer, bbox_lat_min[0]-buffer, bbox_lon_max[0]+buffer, bbox_lat_max[0]+buffer]\n",
    "    bbox = [float_round(x, 10, round)for x in bbox] \n",
    "    # print(bbox)\n",
    "    year = \"2019\"\n",
    "    months = {\n",
    "        \"February\": \"2\",\n",
    "    }\n",
    "\n",
    "    # Change this \n",
    "    time_range = \"2015-03-31/2022-03-30\" #\"2019-03-01/2019-04-30\" # \"2015-03-31/2022-03-30\" # \n",
    "\n",
    "    search = catalog.search(\n",
    "        collections=[\"modis-13A1-061\"],\n",
    "        bbox=bbox,\n",
    "        datetime=time_range,\n",
    "    )\n",
    "    items = list(search.get_items())\n",
    "    print(f\"Found: {len(items):d} datasets\")\n",
    "    items_dict = dict()\n",
    "    for i, item in enumerate(items):\n",
    "        items_dict[i] = item\n",
    "\n",
    "        # %% [markdown]\n",
    "    # ### Get the MODIS composite for a day, and get the average over the EASE grid\n",
    "\n",
    "    # %%\n",
    "    # Get the unique dates from the list of items \n",
    "    unique_dates = []\n",
    "    for i in range(len(items)):\n",
    "        split_itemid = str(items[i]).split(\".\")\n",
    "        unique_dates.append(split_itemid[1])\n",
    "    unique_dates = set(unique_dates)\n",
    "\n",
    "    # Iterate through the unique dates \n",
    "    for i, unique_date in tqdm(enumerate(unique_dates), total=len(unique_dates)):\n",
    "        item_for_the_unique_date = []\n",
    "        \n",
    "        # Create a paired list of granules for the unique date\n",
    "        for j, item in enumerate(items):\n",
    "            if (unique_date in str(item)): \n",
    "                item_for_the_unique_date.append(item)\n",
    "        \n",
    "        # Iterate through the list of granules for the unique date \n",
    "        for k, item in enumerate(item_for_the_unique_date):\n",
    "            \n",
    "            # Read MODIS data from STAC server\n",
    "            MODIS_data0 = stac_load(\n",
    "                [item],\n",
    "                crs=\"EPSG:4326\",\n",
    "                bands=\"500m_16_days_NDVI\",\n",
    "                resolution=0.0045,\n",
    "                bbox=bbox\n",
    "            )\n",
    "\n",
    "            MODIS_QA0 = stac_load(\n",
    "                [item],\n",
    "                crs=\"EPSG:4326\",\n",
    "                bands=\"500m_16_days_pixel_reliability\",\n",
    "                resolution=0.0045,\n",
    "                bbox=bbox\n",
    "            )\n",
    "\n",
    "            # MODIS_QA = MODIS_QA0['500m_16_days_pixel_reliability']\n",
    "            \n",
    "            # Scale the data \n",
    "            raster = item.assets[\"500m_16_days_NDVI\"].extra_fields[\"raster:bands\"]\n",
    "            MODIS_data = MODIS_data0[\"500m_16_days_NDVI\"] * raster[0][\"scale\"]\n",
    "            # https://lpdaac.usgs.gov/documents/621/MOD13_User_Guide_V61.pdf\n",
    "\n",
    "            # -1 Fill/No Data Not Processed\n",
    "            # 0 Good Data Use with confidence\n",
    "            # 1 Marginal data Useful, but look at other QA information\n",
    "            # 2 Snow/Ice Target covered with snow/ice\n",
    "            # 3 Cloudy Target not visible, covered with cloud\n",
    "            # 4 Estimated From MODIS historic time series\n",
    "\n",
    "            # Merge the data \n",
    "            if k==0:\n",
    "                MODIS_dataset = MODIS_data\n",
    "                MODIS_QAset = MODIS_QA0['500m_16_days_pixel_reliability']\n",
    "            else:\n",
    "                MODIS_dataset = MODIS_dataset.combine_first(MODIS_data)\n",
    "                MODIS_QAset = MODIS_QAset.combine_first(MODIS_QA0['500m_16_days_pixel_reliability'])\n",
    "            \n",
    "            MODIS_dataset = MODIS_dataset.where(MODIS_QAset==0)\n",
    "            # MODIS_dataset.plot.imshow(cmap=\"viridis\", col=\"time\")\n",
    "\n",
    "            # Take an average over the grid\n",
    "            if k==len(item_for_the_unique_date)-1:\n",
    "                MODIS_dataset = MODIS_dataset.rename({'longitude': 'x', 'latitude': 'y'})\n",
    "                MODIS_dataset_clipped = MODIS_dataset.rio.clip_box(minx=bbox_lon_min[0], miny=bbox_lat_min[0], maxx=bbox_lon_max[0], maxy=bbox_lat_max[0]).copy()\n",
    "                # MODIS_dataset.plot.imshow(cmap=\"viridis\", col=\"time\", vmin=0, vmax=1)\n",
    "                # MODIS_dataset_clipped.plot.imshow(cmap=\"viridis\", col=\"time\", vmin=0, vmax=1)\n",
    "                mean_over_SMAPgrid0 = MODIS_dataset.mean(dim=[\"x\", \"y\"],skipna=True)\n",
    "                mean_over_SMAPgrid1 = pd.DataFrame([[mean_over_SMAPgrid0.time.values[0], mean_over_SMAPgrid0.values[0]]], columns=['Date', 'MODISmeanNDVI_SMAPgrid'])\n",
    "                mean_over_SMAPgrid1['Date'] = pd.to_datetime(mean_over_SMAPgrid1['Date'])\n",
    "                mean_over_SMAPgrid1.set_index('Date', inplace=True)\n",
    "                if i==0:\n",
    "                    mean_ts = mean_over_SMAPgrid1\n",
    "                else:\n",
    "                    mean_ts = pd.concat([mean_ts, mean_over_SMAPgrid1])\n",
    "\n",
    "    mean_ts_daily = mean_ts['MODISmeanNDVI_SMAPgrid'].resample('D', axis=0).interpolate()\n",
    "    mean_ts_daily.plot()\n",
    "\n",
    "    if not os.path.exists(os.path.join(input_path, modis_ndvi_path, network_name.replace(\" \", \"_\"))):\n",
    "        os.makedirs(os.path.join(input_path, modis_ndvi_path, network_name.replace(\" \", \"_\")))\n",
    "    file_path = os.path.join(input_path, modis_ndvi_path, network_name.replace(\" \", \"_\"), f'daily_NDVI_{target_station}.csv')\n",
    "    mean_ts_daily.to_csv(file_path, header=True, index=True)              \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMAP_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
